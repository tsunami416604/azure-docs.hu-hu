<properties
    pageTitle="Azure 進階儲存體：專為效能而設計 | Microsoft Azure"
    description="使用 Azure 進階儲存體設計高效能應用程式。 「進階儲存體」可針對在「Azure 虛擬機器」上執行且需要大量 I/O 的工作負載，提供高效能、低延遲的磁碟支援。"
    services="storage"
    documentationCenter="na"
    authors="ms-prkhad"
    manager=""
    editor=""/>

<tags
    ms.service="storage"
    ms.workload="storage"
    ms.tgt_pltfrm="na"
    ms.devlang="na"
    ms.topic="article"
    ms.date="12/04/2015"
    ms.author="robinsh"/>

# Azure 進階儲存體：專為高效能而設計

## 概觀  
這篇文章提供使用 Azure 進階儲存體來建置高效能應用程式的指導方針。 您可以使用這份文件所提供的指示，並根據您的應用程式所採用的技術，結合適合的效能最佳作法。 為了說明指導方針，在這整份文件中，我們以進階儲存體上執行的 SQL Server 為範例。

雖然我們在本文中說明儲存體層的效能案例，但您必須將應用程式層最佳化。 例如，如果您在 Azure 進階儲存體上裝載 SharePoint 伺服器陣列，您可以使用本文件的 SQL Server 範例將資料庫伺服器最佳化。 此外，也要將 SharePoint 伺服器陣列的 Web 伺服器和應用程式伺服器最佳化，才能發揮最高效能。

關於在 Azure 進階儲存體上將應用程式效能最佳化方面，本文有助於回答以下常見的問題。

-   如何衡量應用程式效能？  
-   為什麼看不到預期的高效能？  
-   哪些因素會影響進階儲存體上的應用程式效能？  
-   這些因素如何影響進階儲存體上的應用程式效能？  
-   如何最佳化 IOPS、頻寬和延遲？  

我們特別針對進階儲存體提供這些指導方針，因為進階儲存體上執行的工作負載非常重視效能。 我們在適當的地方都提供範例。 針對在具有標準儲存體磁碟的 IaaS VM 上執行的應用程式，您也可以運用這些指導方針。

在開始，如果您不熟悉到高階儲存體之前，先閱讀 [高階儲存體簡介](storage-premium-storage-preview-portal.md) 文章和 [Azure 高階儲存體延展性和效能目標](storage-scalability-targets.md#scalability-targets-for-premium-storage-accounts)。

## 應用程式效能指標  
我們使用效能指標來評估應用程式執行是否順暢，例如，應用程式多快處理使用者要求、應用程式在每個要求中處理多少資料、應用程式在一段特定時間內處理多少要求、使用者提交要求之後必須等候少久才獲得回應。 這些效能指標的技術性術語包括 IOPS、輸送量或頻寬及延遲。

在本節中，我們將討論進階儲存體的一般效能指標。 在下一節「收集應用程式需求」中，您將學習如何對您的應用程式測量這些效能指標。 稍後在「最佳化應用程式效能」中，您將了解影響這些效能指標的因素，以及最佳化建議。

## IOPS  
IOPS 是指應用程式在一秒內傳送到儲存體磁碟的要求數。 輸入/輸出作業可能是讀取或寫入、循序或隨機。 線上零售網站之類的 OLTP 應用程式需要立即處理許多並行使用者要求。 使用者要求是頻繁插入和更新的資料庫交易，應用程式必須快速處理。 因此，OLTP 應用程式需要極高的 IOPS。 這類應用程式處理數百萬個小型和隨機的 IO 要求。 如果您有這類應用程式，您必須以 IOPS 最佳化為重點，設計應用程式基礎結構。 在後面小節中， *最佳化應用程式效能*, ，我們探討所有取得高 IOPS 時，您必須考慮的因素。

當您將進階儲存體磁碟連接至高延展性 VM 時，Azure 會根據磁碟規格，保證佈建一定數量的 IOPS。 例如，P30 磁碟會佈建 5000 IOPS。 每個高延展性 VM 大小也有它可承受的特定 IOPS 限制。 例如，標準 GS5 VM 以 80,000 IOPS 為限。

## 輸送量  
輸送量或頻寬是指應用程式在指定的間隔內傳送到儲存體磁碟的資料量。 如果應用程式以較大 IO 單位大小執行輸入/輸出作業，則需要較高輸送量。 資料倉儲應用程式通常會發出一次存取大量資料的頻繁掃描作業，而且經常執行大量作業。 換句話說，這類應用程式需要較高的輸送量。 如果您有這類應用程式，您必須以輸送量最佳化為重點來設計基礎結構。 下一節，我們將詳細討論必須調整哪些因素，才能達到此目的。

當您將進階儲存體磁碟連接至高延展性 VM 時，Azure 會根據該磁碟規格來佈建輸送量。 例如，P30 磁碟會佈建每秒 200 MB 的磁碟輸送量。 每個高延展性 VM 大小也有它可承受的特定輸送量限制。 例如，標準 GS5 VM 的輸送量上限為每秒 2,000 MB。

輸送量和 IOPS 之間存在某種關聯，如下列公式所示。

![](media/storage-premium-storage-performance/image1.png)

因此，務必判斷應用程式所需的最佳輸送量和 IOPS 值。 嘗試最佳化其中一個時，另一個也會受影響。 在稍後的章節， *最佳化應用程式效能*, ，我們會最佳化 IOPS 和輸送量的討論更多詳細資料。

## 延遲  
延遲是指應用程式收到單一要求、將它傳送至儲存體磁碟，然後將回應傳送給用戶端所花費的時間。 除了 IOPS 和輸送量，這也是應用程式效能的一個重要量值。 進階儲存體磁碟的延遲是指擷取要求的資訊並傳回給應用程式所花費的時間。 進階儲存體提供一致的低延遲。 如果在進階儲存體磁碟上啟用 ReadOnly 主機快取，讀取延遲會非常低。 我們將討論磁碟快取在稍後的章節詳細上 *最佳化應用程式效能*。

當您將應用程式最佳化以產生較高的 IOPS 和輸送量時，也會影響應用程式的延遲。 調整應用程式效能之後，務必評估應用程式的延遲，以避免發生非預期的高延遲現象。

## 收集應用程式效能需求  
設計 Azure 進階儲存體上執行的高效能應用程式時，第一步是了解應用程式的效能需求。 收集效能需求之後，您就可以將應用程式最佳化，以達到最佳效能。

在上一節，我們已說明一般效能指標：IOPS、輸送量和延遲。 為了讓應用程式提供理想的使用者體驗，您必須識別哪些是重要的效能指標。 例如，就每秒處理數百萬個交易的 OLTP 應用程式而言，高 IOPS 最重要。 然而，就每秒處理大量資料的資料倉儲應用程式而言，高輸送量很重要。 就即時視訊串流處理網站之類的即時應用程式而言，極低的延遲非常重要。

接下來，測量應用程式在整個存留期的最高效能需求。 使用下列檢查清單範例作為起點。 記錄正常、尖峰和離峰工作負載期間的最高效能需求。 只要識別所有工作負載層級的需求，您就可以判斷應用程式的整體效能需求。 例如，電子商務網站的正常工作負載是它的一年中大部分日子處理的交易。 網站的尖峰工作負載是它在節慶季節或特殊銷售活動期間所處理的交易。 尖峰工作負載的期間通常很短，但應用程式可能需要調升為正常作業的兩倍以上。 請找出 50 百分位數、90 百分位數和 99 百分位數的需求。 這有助於篩選掉效能需求的任何極端值，讓您專注於最佳化正確的值。

**應用程式效能需求檢查清單**

| **效能需求** | **50 百分位數** | **90 百分位數** | **99 個百分位數** |
|---|---|---|---|
| 最大 每秒交易 | | | |
| % 讀取作業            | | | |
| % 寫入作業           | | | |
| % 隨機作業          | | | |
| % 循序作業      | | | |
| IO 要求大小              | | | |
| 平均輸送量           | | | |
| 最大 輸送量              | | | |
| 最小 延遲                 | | | |
| 平均延遲              | | | |
| 最大 CPU                     | | | |
| 平均 CPU                  | | | |
| 最大 記憶體                  | | | |
| 平均記憶體               | | | |
| 佇列深度                  | | | |

>**重要事項：**  
>您應該考慮調整這些數字，根據您的應用程式的預期未來的成長。 最好事先為成長預做規劃，因為以後再變更基礎結構來改善效能會較困難。

如果您有現有的應用程式，而且想要移到進階儲存體，請先為現有的應用程式建立上述檢查清單。 然後，建置的高階儲存體上的應用程式原型，並設計的應用程式中所述的指導方針 *最佳化應用程式效能* 在本文件稍後的章節。 下一節說明可用來收集效能度量單位的工具。

為原型建立一份類似於現有應用程式的檢查清單。 您可以使用效能評定工具，在原型應用程式上模擬工作負載並測量效能。 請參閱 〈 *Benchmarking* 若要深入了。 這樣做可讓您判斷進階儲存體是否符合或超越應用程式效能需求。 然後，您可以對實際執行的應用程式運用相同的指導方針。

### 測量應用程式效能需求的計數器  
如果要測量應用程式的效能需求，最佳方式就是使用伺服器的作業系統所提供的效能監視工具。 您可以使用 Windows 的 PerfMon 和 Linux 的 iostat。 這些工具可擷取與上一節所述的每個量值相對應的計數器。 當應用程式執行正常、尖峰和離峰工作負載時，您必須在擷取這些計數器的值。

伺服器的處理器、記憶體及每個邏輯磁碟和實體磁碟，都有可用的 PerfMon 計數器。 當您使用進階儲存體磁碟和 VM 時，實體磁碟計數器適用於每個進階儲存體磁碟，邏輯磁碟計數器適用於進階儲存體上建立的每個磁碟區。 您必須為裝載應用程式工作負載的磁碟擷取這些值。 如果邏輯與實體磁碟之間有一對一對應，您可以參考實體磁碟計數器，否則請參考邏輯磁碟計數器。 在 Linux 上，iostat 命令會產生 CPU 和磁碟使用率報告。 磁碟使用率報告提供每個實體裝置或分割區的統計資料。 如果資料庫伺服器的資料和記錄位於不同磁碟上，請同時從這兩個磁碟中收集這項資料。 下表說明磁碟、處理器和記憶體的計數器：

| 計數器 | 說明 | PerfMon | Iostat |
|---|---|---|---|
| **IOPS 或每秒交易數** | 每秒發出給儲存體磁碟的 I/O 要求數。 | Disk Reads/sec <br> Disk Writes/sec | tps <br> r/秒 <br> w/秒 |
| **磁碟讀取和寫入** | 磁碟上執行的讀取和寫入作業 %。 | %磁碟讀取時間 <br> %Disk Write Time | r/秒 <br> w/秒 |
| **輸送量** | 每秒讀取或寫入磁碟的資料量。 | 磁碟讀取位元組/秒 <br> 磁碟寫入位元組/秒 | kB_read/秒 <br> kB_wrtn/秒 |
| **延遲** | 完成磁碟 IO 要求的總時間。 | Average Disk sec/Read <br> 平均磁碟秒寫入 | 等候 <br> svctm |
| **IO 大小** | 發出給儲存體磁碟的 I/O 要求大小。 | 磁碟的平均位元組/讀取 <br> 磁碟的平均位元組/寫入 | avgrq-sz |
| **佇列深度** | 等候讀取或寫入儲存體磁碟的未完成 I/O 要求數。 | 目前磁碟佇列長度 | avgqu-sz |
| **最大 記憶體** | 順暢執行應用程式所需的記憶體數量 | % Committed Bytes in Use | Use vmstat |
| **最大 CPU** | 順暢執行應用程式所需的 CPU 數量 | % Processor time | %util |

深入了解 [iostat](http://linuxcommand.org/man_pages/iostat1.html) 和 [PerfMon](https://msdn.microsoft.com/library/aa645516.aspx)。


## 最佳化應用程式效能  
對進階儲存體上執行的應用程式，影響效能的主要因素包括 IO 要求的本質、VM 大小、磁碟大小、磁碟數目、磁碟快取、多執行緒處理和佇列深度。 您可以使用系統提供的參數來控制這些因素。 大部分應用程式可能沒有選項讓您直接改變 IO 大小和佇列深度。 例如，如果您使用 SQL Server，您無法選擇 IO 大小和佇列深度。 SQL Server 會選擇最佳 IO 大小和佇列深度值，以獲得最高效能。 務必了解這兩種因素對應用程式效能的影響，才能佈建適當的資源來滿足效能需求。

在本節中，請參閱您建立的應用程式需求檢查清單，以識別您需要將應用程式效能最佳化到何種程度。 據此，您將能夠判斷需要調整本節中的哪些因素。 若要證明每個因素對應用程式效能的影響，請在應用程式安裝上執行效能評定工具。 請參閱 [Benchmarking](#_Benchmarking) 步驟 Windows 和 Linux Vm 上執行一般效能評定工具這篇文章的最後一節。

### 最佳化 IOPS、輸送量和延遲的速覽  
下表摘要說明所有效能因素和最佳化 IOPS、輸送量和延遲的步驟。 這份摘要之後的幾節更深入說明每一個因素。

| | **IOPS** | **輸送量** | **延遲** |
|---|---|---|---|
| **範例案例** | 需要極高每秒交易速率的企業 OLTP 應用程式。                                                                                                                                 | 處理大量資料的企業資料倉儲應用程式。 | 需要立即回應使用者要求的近乎即時的應用程式，例如線上遊戲。 |
| 效能因素  | | | |
| **IO 大小** | 較小 IO 大小會產生較高的 IOPS。                                                                                                                                                                           | 較大 IO 大小會產生較高的輸送量。 | |
| **VM 大小** | 使用 IOPS 大於應用程式需求的 VM 大小。 請參閱這裡的 VM 大小及其 IOPS 限制。 | 使用輸送量限制大於應用程式需求的 VM 大小。 請參閱這裡的 VM 大小及其輸送量限制。 | 使用調整限制大於應用程式需求的 VM 大小。 請參閱這裡的 VM 大小及其限制。 |
| **磁碟大小** | 使用 IOPS 大於應用程式需求的磁碟大小。 請參閱這裡的磁碟大小及其 IOPS。 | 使用輸送量限制大於應用程式需求的磁碟大小。 請參閱這裡的磁碟大小及其輸送量限制。 | 使用調整限制大於應用程式需求的磁碟大小。 請參閱這裡的磁碟大小及其限制。 |
| **VM 和磁碟調整限制** | 選擇的 VM 大小的 IOPS 限制，應該大於它連接的進階儲存體磁碟所推動的 IOPS 總數。 | 選擇的 VM 大小的輸送量限制，應該大於它連接的進階儲存體磁碟所推動的輸送量總數。 | 選擇的 VM 大小的調整限制，必須大於連接的進階儲存體磁碟的調整限制總數。 |
| **磁碟快取** | 在讀取作業繁重的進階儲存體磁碟上，啟用唯讀快取可產生較高的讀取 IOPS。 | | 在讀取作業繁重的進階儲存體磁碟上，啟用唯讀快取可產生極低的讀取延遲。 |
| **磁碟串接** | 使用多個磁碟並串接在一起，可結合產生較高的 IOPS 和輸送量限制。 請注意，每個 VM 的結合限制應該高於連接的高階磁碟的結合限制。 | |
| **等量大小** | 在 OLTP 應用程式中，隨機小型 IO 模式使用較小的等量大小。 例如，SQL Server OLTP 應用程式使用等量大小 64KB。 | 在資料倉儲應用程式中，循序大型 IO 模式使用較大的等量大小。 例如，SQL Server 資料倉儲應用程式使用 256KB 等量大小。 | |
| **多執行緒處理** | 使用多執行緒處理將較多要求推送至進階儲存體，將會產生較高的 IOPS 和輸送量。 例如，在 SQL Server 上設定較高的 MAXDOP 值，可配置更多 CPU 給 SQL Server。 | |
| **佇列深度** | 較大佇列深度會產生較高的 IOPS。 | 較大佇列深度會產生較高的輸送量。 | 較小佇列深度會產生較低的延遲。 |

## IO 要求的本質  
IO 要求是指應用程式執行的輸入/輸出作業單位。 識別 IO 要求的本質、隨機或循序、讀取或寫入、小型或大型，可協助您判斷應用程式的效能需求。 設計應用程式基礎結構時，務必了解 IO 要求的本質，才能做出正確的決策。

IO 大小是其中一個很重要的因素。 IO 大小是指應用程式所產生的輸入/輸出作業要求的大小。 IO 大小對效能有很重大的影響，特別是應用程式可達到的 IOPS 和頻寬。 下列公式會顯示 IOPS，之間的關聯性 IO 大小和頻寬/輸送量。  
    ![](media/storage-premium-storage-performance/image1.png)

有些應用程式可讓您改變 IO 大小，而有些應用程式則不能改變。 例如，SQL Server 會自行決定最佳的 IO 大小，不提供任何參數讓使用者變更 IO 大小。 相反地，Oracle 提供參數，稱之為 [DB\_BLOCK\_SIZE](https://docs.oracle.com/cd/B19306_01/server.102/b14211/iodesign.htm#i28815) 使用，您可設定資料庫的 I/O 要求大小。

如果您使用的應用程式不允許變更 IO 大小，請根據本文中的指導方針，將應用程式最相關的效能 KPI 最佳化。 例如，

-   OLTP 應用程式會產生數百萬個小型和隨機的 IO 要求。 若要處理這種 IO 要求，您必須以提高 IOPS 為重點，設計應用程式基礎結構。  
-   資料倉儲應用程式會產生大型和循序的 IO 要求。 若要處理這種 IO 要求，您必須以提高頻寬和輸送量為重點，設計應用程式基礎結構。

如果您使用的應用程式可讓您變更 IO 大小，除了參考其他效能指導方針，請利用此基本原則來決定 IO 大小。

-   較小 IO 大小會產生較高的 IOPS。 例如，OLTP 應用程式使用 8 KB。  
-   較大 IO 大小會產生較高的頻寬/輸送量。 例如，資料倉儲應用程式使用 1024 KB。

以下是如何計算應用程式的 IOPS 和輸送量/頻寬的範例。 假設應用程式使用 P30 磁碟。 P30 磁碟可以達到的最大 IOPS 和輸送量/頻寬，分別為 5000 IOPS 和每秒 200 MB。 現在，如果應用程式需要 P30 磁碟的最大 IOPS，但您使用較小的 IO 大小，例如 8 KB，則能夠達到的頻寬為每秒 40 MB。 不過，如果應用程式需要 P30 磁碟的最大輪送量/頻寬，而且您使用較大的 IO 大小，例如 1024 KB，則產生的 IOPS 較小，只有 200 IOPS。 因此，請將 IO 大小調整為同時滿足應用程式的 IOPS 和輸送量/頻寬需求。 下表摘要說明 P30 磁碟的不同 IO 大小及其對應的 IOPS 和輸送量。

| **應用程式需求** | **I/O 大小** | **IOPS** | **輸送量/頻寬** |
|-----------------------------|--------------|----------|--------------------------|
| 最大 IOPS                    | 8 KB         | 5,000    | 每秒 40 MB         |
| 最大輸送量              | 1024 KB      | 200      | 每秒 200 MB        |
| 最大輸送量 + 高 IOPS  | 64 KB        | 3,200    | 每秒 200 MB        |
| 最大 IOPS + 高輸送量  | 32 KB        | 5,000    | 每秒 160 MB        |

若要讓 IOPS 和頻寬高於單一進階儲存體磁碟的最大值，請使用多個串接在一起的進階磁碟。 例如，串接兩個 P30 磁碟可產生 10,000 IOPS 的結合 IOPS，或每秒 400 MB 的結合輸送量。 如下一節所述，您使用的 VM 大小必須支援結合的磁碟 IOPS 和輸送量。

>**注意：**  
>當您增加 IOPS 或其他也會增加的輸送量，請確定您不觸及輸送量或磁碟或 VM 的 IOPS 限制時增加其中一個。

若要證明 IO 大小對應用程式效能的影響，您可以在 VM 和磁碟上執行效能評定工具。 請建立多個測試回合，而且每個回合使用不同的 IO 大小，以查看影響。 請參閱 [Benchmarking](#_Benchmarking) 這篇文章以取得詳細資料的最後一節。

## 高延展性 VM 大小  
開始設計應用程式時，首要工作之一是選擇 VM 來裝載應用程式。 進階儲存體提供高延展性 VM 大小，可以執行需要更高計算能力和較高本機磁碟 I/O 效能的應用程式。 這些 VM 為本機磁碟提供更快的處理器、較高的記憶體與核心比率，以及固態硬碟 (SSD)。 舉例來說，DS 和 GS 系列 VM 就是支援進階儲存體的高延展性 VM。

高延展性 VM 有各種不同大小，以及不同數目的 CPU 核心、記憶體、作業系統和暫存磁碟大小。 每個 VM 大小也規定您可連接至 VM 的資料磁碟數目上限。 因此，選擇的 VM 大小會影響應用程式可用的處理、記憶體和儲存體容量。 也會影響計算和儲存體成本。 例如，以下為 DS 系列和 GS 系列中最大 VM 大小的規格：

| VM 大小 | CPU 核心 | 記憶體 | VM 磁碟大小 | 最大 資料磁碟 | 快取大小 | IOPS | 頻寬快取 IO 限制 |
|---|---|---|---|---|---|---|---|
| Standard_DS14 | 16 | 112 GB | 作業系統 = 1023 GB <br> 本機 SSD = 224 GB | 32 | 576 GB | 50,000 IOPS <br> 每秒 512 MB | 4,000 IOPS 和每秒 33 MB |
| Standard_GS5 | 32 | 448 GB | 作業系統 = 1023 GB <br> 本機 SSD = 896 GB | 64 | 4224 GB | 80000 IOPS <br> 每秒 2000 MB | 5,000 IOPS 和每秒 50 MB |

若要檢視所有可用的 Azure VM 大小的完整清單，請參閱 [Azure 虛擬機器的大小](virtual-machines-size-specs.md)。 選擇可以符合並調整為期望的應用程式效能需求的 VM 大小。 此外，選擇 VM 大小時，請將下列重要因素納入考量。

*小數位數的限制*  
每個 VM 和每個磁碟的最大 IOPS 限制是不同且各自獨立。 請確定應用程式在 VM 及它連接的高階磁碟的限制內推動 IOPS。 否則，應用程式效能會發生節流現象。

例如，假設應用程式需求是最高 4,000 IOPS。 為了達到此目的，您在 DS1 VM 上佈建 P30 磁碟。 P30 磁碟最高可以達到 5,000 IOPS。 但是，DS1 VM 受限於 3,200 IOPS。 因此，應用程式效能會受到 VM 限制而降到 3,200 IOPS，效能將會降低。 為了避免這種情況，請選擇可同時滿足應用程式需求的 VM 和磁碟大小。

*操作的成本*  
在許多情況下，就可以使用高階儲存體操作的整體成本會低於使用 Standard 儲存體。

例如，假設應用程式需要 16,000 IOPS。 若要達到這樣的效能，您必須讓 16000 使用 32 個標準儲存體 1 TB 磁碟最大 IOPS Standard\_D14 Azure IaaS VM。 每個 1TB 標準儲存體磁碟最高可達到 500 IOPS。 此 VM 的每月預估成本為 $1,570。 32 個標準儲存體磁碟的每月成本為 $1,638。 預估每月總成本為 $3,208。

不過，如果將相同的應用程式裝載於進階儲存體，則只需要較小的 VM 大小和較少的進階儲存體磁碟，因此可降低整體成本。 Standard\_DS13 VM 可以滿足 16000 使用四個 P30 磁碟的 IOPS 需求。 DS13 VM 的最大 IOPS 為 25,600，每個 P30 磁碟的最高 IOPS 為 5,000。 整體來說，這項設定可以達到 5,000 x 4 = 20,000 IOPS。 此 VM 的每月預估成本為 $1,003。 四個 P30 進階儲存體磁碟的每月成本為 $544.34。 預估每月總成本為 $1,544。

下表以標準和進階儲存體來摘要說明此案例的成本明細。

| | **標準** | **高級** |
|---|---|---|
| **每月的 VM 成本** | $ 1,570.58 (Standard\_D14)   | $ 1,003.66 (Standard\_DS13) |
| **每月的磁碟成本** | $1,638.40 (32 x 1 TB 磁碟) | $544.34 (4 x P30 磁碟) |
| **每月的整體成本**  | $3,208.98 | $1,544.34 |

*Linux 散發套件*  
使用 Azure 高階儲存體，可以取得相同的 Vm 的效能層級執行 Windows 和 Linux。 我們支援許多種 Linux 散發版本，而您所見的完整清單 [這裡](virtual-machines-linux-endorsed-distributions.md)。 務必注意，針對不同類型的工作負載，不同的散發版本會更適合。 根據執行工作負載的散發版本而定，您會看到不同層級的效能。 請以您的應用程式來測試 Linux 散發版本，選擇最適合的散發版本。

搭配進階儲存體執行 Linux 時，請檢查所需驅動程式的最新更新，以確保達到較高效能。

## 進階儲存體磁碟大小  
Azure 進階儲存體目前提供三種磁碟大小。 對於 IOPS、頻寬和儲存體，每個磁碟大小各有不同的調整限制。 請根據應用程式需求和高延展性 VM 大小，選擇正確的進階儲存體磁碟大小。 下表顯示三種磁碟大小及其功能。

| **磁碟類型**       | **P10**           | **P20**           | **P30**           |
|---------------------|-------------------|-------------------|-------------------|
| 磁碟大小           | 128 GB           | 512 GB           | 1024 GB (1 TB)   |
| 每一磁碟的 IOPS       | 500               | 2300              | 5000              |
| 每一磁碟的輸送量 | 每秒 100 MB | 每秒 150 MB | 每秒 200 MB |

您選擇的磁碟數量取決於已選擇的磁碟大小。 您可以使用單一 P30 磁碟或多個 P10 磁碟，以滿足應用程式需求。 做決定時，請將下列因素納入考量。

*小數位數的限制 （IOPS 和輸送量）*  
每個高階磁碟大小的 IOPS 和輸送量限制是不同且獨立從 VM 小數位數限制。 請確定磁碟的 IOPS 和輸送量合計，不超過所選擇的 VM 大小的調整限制。

例如，如果應用程式需求是輸送量上限 250 MB/秒，而且您使用 DS4 VM 搭配單一 P30 磁碟。 DS4 VM 最高可以達到 256 MB/秒的輸送量。 不過，單一 P30 磁碟有 200 MB/sec 輸送量限制。 因此，應用程式將會限制在 200 MB/秒，因為磁碟的限制。 為了克服這項限制，請將一個以上的資料磁碟佈建到 VM。

>**注意：**  
>由快取讀取未納入磁碟 IOPS 和輸送量，因此不受磁碟的限制。 對於每個 VM，快取有其個別的 IOPS 和輸送量限制。
>
>例如，剛開始時，讀取和寫入分別為 60 MB/秒和 40 MB/秒。 經過一段時間，快取已活絡，可服務越來越多的讀取。 於是，來自磁碟的寫入輸送量就更高。

*磁碟數目*  
決定您將需要評估應用程式需求的磁碟數目。 每個 VM 大小也會限制您可連接至 VM 的磁碟數目。 這通常是核心數目的兩倍。 請確定您選擇的 VM 大小可以支援所需的磁碟數目。

請記住，相較於標準儲存體磁碟，進階儲存體磁碟有較高效能的功能。 因此，如果您將應用程式從使用標準儲存體的 Azure IaaS VM 移轉至進階儲存體，可能只需要較少的高階磁碟，應用程式就能達到相同或更高的效能。

## 磁碟快取  
採用 Azure 進階儲存體的高延展性 VM 有一項稱為 BlobCache 的多層快取技術。 BlobCache 結合虛擬機器 RAM 和本機 SSD 進行快取。 此快取適用於進階儲存體永續性磁碟和 VM 本機磁碟。 根據預設，針對作業系統磁碟，此快取設定會設為讀取/寫入，而針對裝載於進階儲存體的資料磁碟，則設為唯讀。 在進階儲存體上啟用磁碟快取時，高延展性 VM 可以達到極高的效能層級，超過基礎磁碟效能。

若要深入了解 BlobCache 的運作方式，請參閱內部 [Azure 高階儲存體](https://azure.microsoft.com/blog/azure-premium-storage-now-generally-available-2/) 部落格文章。

務必在正確的一組磁碟上啟用快取。 高階磁碟上是否應該啟用磁碟快取，取決於磁碟將處理的工作負載模式。 下表顯示作業系統磁碟和資料磁碟的預設快取設定。

| **磁碟類型** | **預設快取設定** |
|---|---|
| 作業系統磁碟 | 讀寫 |
| 資料磁碟 | None |

以下是針對資料磁碟建議的磁碟快取設定，

| **磁碟快取設定** | **使用這項設定的建議時機** |
|---|---|
| None | 針對唯寫和大量寫入的磁碟，將主機快取設定為「無」。 |
| 唯讀 | 針對唯讀和讀寫的磁碟，將主機快取設定為「唯讀」。 |
| 讀寫 | 只有當應用程式適當地處理時所需的永續性磁碟寫入快取的資料，請設定主機快取為 ReadWrite。 |

*唯讀*  
藉由設定唯讀快取的高階儲存體資料磁碟，即可達到低讀取延遲，並取得應用程式非常高的讀取 IOPS 和輸送量。 這是基於兩個理由，

1.  從快取執行的讀取 (在 VM 記憶體和本機 SSD 上)，速度遠快於從資料磁碟讀取 (在 Azure Blob 儲存體上)。  
2.  進階儲存體不會將快取所服務的讀取計入磁碟 IOPS 和輸送量之內。 因此，應用程式能夠達到較高的 IOPS 和輸送量總計。

*讀寫*  
根據預設，作業系統磁碟有 ReadWrite 啟用快取。 我們最近也已在資料磁碟上增加支援「讀寫」快取。 如果您使用「讀寫」快取，您必須有適當的方法將快取中的資料寫入永續性磁碟。 例如，SQL Server 會自行負責將快取的資料寫入永續性儲存體磁碟。 對於不負責保存必要資料的應用程式，如果使用「讀寫」快取，一旦 VM 損毀，可能會導致資料遺失。

舉例來說，您可以執行下列動作，將這些指導方針運用在進階儲存體上執行的 SQL Server，

1.  在裝載資料檔案的 premium 儲存體磁碟上設定"ReadOnly"快取。  
    a.  快速從較低的快取讀取資料頁會從快取擷取速度快上許多，因為 SQL Server 查詢時間相較於直接從資料磁碟。  
    b.  由快取來服務讀取，表示高階資料磁碟會有額外的輸送量可用。 SQL Server 可以使用這個額外的輸送量來擷取更多資料頁和執行其他作業，例如備份/還原、批次載入和索引重建。  
2.  設定 「 無 」 上主控記錄檔的高階儲存體磁碟快取。  
    a.  記錄檔以大量寫入的作業為主。 因此，無法從「唯讀」快取中受惠。

## 磁碟串接  
當高延展性 VM 連接數個進階儲存體永續性磁碟時，磁碟可以串接在一起，以彙總其 IOPS、頻寬和儲存體容量。

在 Windows 中，您可以使用「儲存空間」將磁碟串接在一起。 您必須為集區中的每個磁碟設定一欄。 否則，由於磁碟之間的流量分配不平均，等量磁碟區的整體效能可能會低於預期。

重要事項：您可以使用伺服器管理員 UI，將一個等量磁碟區的總欄數最多設定為 8 個。 當連接 8 個以上的磁碟時，請使用 PowerShell 來建立磁碟區。 您可以使用 PowerShell 將欄數設定為等於磁碟數量。 例如，如果單一等量集; 有 16 個磁碟指定在 16 個資料行 *NumberOfColumns* 參數 *New-virtualdisk* PowerShell cmdlet。

在 Linux 上，請使用 MDADM 公用程式將磁碟串接在一起。 請參閱在 Linux 上的等量磁碟上的詳細的步驟， [在 Linux 上設定軟體 RAID](virtual-machines-linux-configure-raid.md)。

*等量大小*  
等量磁碟區大小為磁碟條狀配置中的設定不重要。 等量大小或區塊大小是指應用程式在等量磁碟區上可定址的最小資料區塊。 您設定的等量大小取決於應用程式的類型及其要求模式。 如果您選擇錯誤的等量大小，可能會導致 IO 對齊錯錯，進而導致應用程式的效能降低。

比方說，如果應用程式所產生的 IO 要求大於磁碟等量大小，儲存體系統會跨越等量單位界限，將此要求寫入多個磁碟上。 在需要存取該資料時，必須跨越一個以上的等量單位來搜尋，才能完成要求。 這種行為的累積效果可能會導致效能大幅降低。 相反地，如果 IO 要求大小比等量大小更小，而且是隨機性質，IO 要求可能聚集在相同的磁碟上而造成瓶頸，最終導致 IO 效能降低。

請根據應用程式執行的工作負載類型，選擇適當的等量大小。 對於隨機小型 IO 要求，請使用較小的等量大小。 對於大型循序 IO 要求，請使用較大的等量大小。 針對您要在進階儲存體上執行的應用程式，請參考等量大小建議。 對於 SQL Server 而言，請將 OLTP 工作負載的等量大小設定為 64KB，而資料倉儲工作負載則設定為 256KB。 請參閱 [的 Azure Vm 上的 SQL Server 效能最佳作法](virtual-machines-sql-server-performance-best-practices.md#disks-and-performance-considerations) 若要深入了。

>**注意：**  
>您可以將分割區同時最多 32 個高階儲存體磁碟上的 DS 系列 VM 和 GS 系列 VM 上的 64 高階儲存體磁碟。

## 多執行緒處理  
Azure 已將進階儲存體平台設計為大規模平行。 因此，多執行緒應用程式可達到的效能遠高於單一執行緒應用程式。 多執行緒應用程式會將工作分割成多個執行緒，並竭盡所能利用 VM 和磁碟資源，以提高執行效率。

例如，如果應用程式在單一核心 VM 上使用兩個執行緒執行，CPU 可以在兩個執行緒之間切換以提高效率。 當一個執行緒正在等候磁碟 IO 完成時，CPU 可以切換到另一個執行緒。 如此一來，兩個執行緒可以完成比單一執行緒更多的工作。 如果 VM 有一個以上的核心，則可進一步縮短執行時間，因為每個核心可以平行地執行工作。

您可能無法變更現成應用程式實作單一執行緒或多執行緒的方式。 例如，SQL Server 能夠處理多 CPU 與多核心。 不過，SQL Server 會決定在哪些情況下利用一或多個執行緒來處理查詢。 它可以使用多執行緒來執行查詢和建立索引。 如果查詢需要聯結大型資料表，而且將資料傳回給使用者之前需要排序資料，SQL Server 可能會使用多個執行緒。 但是，使用者無法控制 SQL Server 使用單一執行緒或多個執行緒來執行查詢。

您可以變更組態設定，以影響應用程式的這種多執行緒或平行處理方式。 例如，以 SQL Server 而言，這就是「平行處理原則的最大程度」組態。 這項設定稱為 MAXDOP，可讓您設定 SQL Server 在平行處理時可使用的處理器數目上限。 您可以為個別的查詢或索引作業設定 MAXDOP。 針對重視效能的應用程式，這有益於平衡系統的資源。

例如，假設使用 SQL Server 的應用程式正在同時執行大型查詢和索引作業。 假設您希望索引作業的效能高於大型查詢。 在這種情況下，您可以將索引作業的 MAXDOP 值設為高於查詢的 MAXDOP 值。 如此一來，可供 SQL Server 利用來執行索引作業的處理器數目，就比專用於大型查詢的處理器數目更多。 請記住，您不能控制 SQL Server 用於每個作業的執行緒數目。 您可以控制專用於多執行緒處理的處理器數目上限。

深入了解 [平行處理原則的程度](https://technet.microsoft.com/library/ms188611.aspx) SQL Server 中。 在應用程式及其組態中找出會影響多執行緒處理的設定，以最佳化效能。

## 佇列深度  
「佇列深度」或「佇列長度」或「佇列大小」是指系統中暫止的 IO 要求數目。 佇列深度的值決定應用程式可以排隊的 IO 作業數目，將由儲存體磁碟來處理。 它會影響我們在本文已討論過的所有三個應用程式效能指標，也就是 IOPS、輸送量和延遲。

佇列深度與多執行緒處理密切相關。 佇列深度值指出應用程式可以達到多高的多執行緒處理程度。 如果佇列深度較大，應用程式可以同時執行較多作業，也就是多執行緒處理程度較高。 如果佇列深度較小，即使是多執行緒應用程式，也不會有足夠的要求排隊來同時執行。

通常，現成應用程式不允許您變更佇列深度，因為如果設定不正確，將會弊多於利。 應用程式會設定正確的佇列深度值，以獲得最佳效能。 但是，務必了解此概念，才能對應用程式的效能問題進行疑難排解。 您也可以在系統上執行效能評定工具，以觀察佇列深度的效果。

某些應用程式提供設定來影響佇列深度。 例如，上一節所述 SQL Server 中的 MAXDOP (平行處理原則的最大程度) 設定。 MAXDOP 並不直接變更 SQL Server 的佇列深度值，但卻是影響佇列深度和多執行緒處理的一種方法。

*高佇列深度*  
高佇列深度排列在磁碟上的其他作業。 磁碟會事先知道其佇列中的下一個要求。 因此，磁碟可以事先排定這些作業，並以最佳順序來處理作業。 因為應用程式將更多要求傳送到磁碟，磁碟可以處理更多平行 IO。 最後，應用程式將能夠達到更高的 IOPS。 因為應用程式處理更多的要求，所以應用程式的總輸送量也會提高。

通常，當每個連接的磁碟上有 8-16+ 個未完成的 IO 時，應用程式可以達到最大輸送量。 如果佇列深度是一，則應用程式不會將足夠的 IO 推送至系統，因此在指定期間內處理的數量會較少。 換句話說，輸送量較少。

例如，在 SQL Server 中，將查詢的 MAXDOP 值設為 "4"，就是向 SQL Server 表示它最多可以使用四個核心來執行查詢。 SQL Server 會決定查詢執行的最佳佇列深度值和核心數目。

*最佳的佇列深度*  
非常高的佇列深度值也有缺點。 如果佇列深度值太高，應用程式會嘗試推動非常高的 IOPS。 除非應用程式的永續性磁碟已佈建足夠的 IOPS，否則這可能對應用程式延遲造成負面影響。 下列公式顯示 IOPS、 延遲和佇列深度之間的關聯性。  
    ![](media/storage-premium-storage-performance/image6.png)

不應該只想將佇列深度設定為較高的值，而是應該設定為最佳值，以提供足夠的 IOPS 給應用程式，但又不影響延遲。 例如，如果應用程式延遲必須是 1 毫秒，則達成 5,000 IOPS 所需的佇列深度為 QD = 5000 x 0.001 = 5。

*等量磁碟區的佇列深度*  
等量磁碟區，維護夠高的佇列深度，使每個磁碟分別有尖峰佇列深度。 例如，假設應用程式推送的佇列深度為 2，而等量磁碟區中有 4 個磁碟。 兩個 IO 要求會流向兩個磁碟，而剩餘的兩個磁碟會處於閒置狀態。 因此，請將佇列深度設定為讓所有磁碟都有工作執行。 下列公式會顯示如何判斷佇列深度的等量磁碟區。  
    ![](media/storage-premium-storage-performance/image7.png)

## 節流  
Azure 進階儲存體會根據您選擇的 VM 大小和磁碟大小，佈建指定數目的 IOPS 和輸送量。 每當應用程式嘗試推動的 IOPS 或輸送量超過 VM 或磁碟可處理的這些限制時，進階儲存體便會進行節流。 這會造成應用程式的效能降低。 這可能表示延遲較高、輸送量較低或 IOPS 較低。 如果進階儲存體不會節流，應用程式可能會超出其資源的能力負荷而完全失敗。 因此，為了避免因為節流而造成效能問題，一定要為應用程式佈建足夠的資源。 請考量先前在 VM 大小和磁碟大小各節已討論過的因素。 為了駕馭應用程式，效能評定是找出所需資源的最佳方式。

## 效能評定  
效能評定的過程中會在應用程式上模擬不同工作負載，並測量應用程式在每個工作負載上達到的效能。 您已根據稍早一節所述的步驟來收集應用程式效能需求。 您可以在裝載應用程式的 VM 上執行效能評定工具，以判斷應用程式利用進階儲存體可達成的效能層級。 在本節中，我們針對以 Azure 進階儲存體佈建的標準 DS14 VM，提供效能評定範例。

我們分別在 Windows 和 Linux 上使用一般效能評定工具 Iometer 和 FIO。 這些工具會繁衍多個執行緒來模擬類似實際執行的工作負載，並測量系統效能。 您也可以使用這些工具來設定參數，例如區塊大小和佇列深度，您通常無法在應用程式中變更這些參數。 針對不同類型的應用程式工作負載，這可讓您在以高階磁碟佈建的高延展性 VM 上，更靈活地發揮最大效能。 若要了解每項效能評定工具，請瀏覽 [Iometer](http://www.iometer.org/) 和 [FIO](http://freecode.com/projects/fio)。

若要執行下列範例，請建立標準 DS14 VM，並將 11 個進階儲存體磁碟連接至 VM。 在 11 磁碟中，以快取「無」來設定 10 個磁碟，並將它們串接成一個磁碟區，稱為 NoCacheWrites。 在剩餘的磁碟上，將主機快取設定為「唯讀」，並使用此磁碟建立一個磁碟區，稱為 CacheReads。 根據此設定，您可以看到標準 DS14 VM 發揮最大的讀取和寫入效能。 如需使用 premium 磁碟建立 DS14 VM 的詳細步驟，請移至 [建立和使用高階儲存體帳戶的虛擬機器資料磁碟](storage-premium-storage-preview-portal.md#create-and-use-a-premium-storage-account-for-a-virtual-machine-data-disk)。

*暖機快取*  
具有 ReadOnly 主機快取的磁碟可以提供更高 IOPS 比磁碟的限制。 若要從主機快取獲得這種最高的讀取效能，您必須先準備此磁碟的快取。 如此可確保效能評定工具在 CacheReads 磁碟區上推動的讀取 IO 實際上是命中快取，而非直接觸及磁碟。 快取命中會讓已啟用快取的單一磁碟產生更多 IOPS。

>**重要事項：**  
>您必須準備快取，然後再執行基準測試，每次重新啟動 VM。

#### Iometer   
從這個連結，此連結從 VM 上下載 Iometer 工具 ︰ [下載](http://sourceforge.net/projects/iometer/files/iometer-stable/2006-07-27/iometer-2006.07.27.win32.i386-setup.exe/download)。

*測試檔案*  
Iometer 會使用儲存在您將執行效能評定測試所在的磁碟區的測試檔案。 它會對此測試檔案推動讀取和寫入，以測量磁碟 IOPS 和輸送量。 如果您沒有提供此測試檔案，Iometer 會建立測試檔案。 在 CacheReads 和 NoCacheWrites 磁碟區上，建立一個稱為 iobw.tst 的 200GB 測試檔案。

*存取規格*  
規格要求 IO 大小，%讀取/寫入，%隨機/循序會設定為使用 Iometer 」 存取規格 」 索引標籤。 為以下說明的每個案例建立存取規格。 建立存取規格並將 [儲存] 以適當命名像 RandomWrites\_8K，RandomReads\_8K。 執行測試案例時選取對應的規格。

以下範例的最大寫入 IOPS 案例的存取規格，  
    ![](media/storage-premium-storage-performance/image8.png)

*最大 IOPS 測試規格*  
若要示範的最大 IOPs，使用較小的要求大小。 使用 8K 要求大小，並建立隨機寫入和讀取的規格。

| 存取規格 | 要求大小 | 隨機 % | 讀取 % |
|----------------------|--------------|----------|--------|
| RandomWrites\_8K     | 8K           | 100      | 0      |
| RandomReads\_8K      | 8K           | 100      | 100    |

*最大輸送量測試規格*  
若要示範的最大輸送量，請使用較大的要求大小。 使用 64K 要求大小，並建立隨機寫入和讀取的規格。

| 存取規格 | 要求大小 | 隨機 % | 讀取 % |
|----------------------|--------------|----------|--------|
| RandomWrites\_64K    | 64K          | 100      | 0      |
| RandomReads\_64K     | 64K          | 100      | 100    |

*執行 Iometer 測試*  
執行下列步驟來準備快取

1.  使用如下所示的值建立兩個存取規格

  	| 名稱              | 要求大小 | 隨機 % | 讀取 % |
  	|-------------------|--------------|----------|--------|
  	| RandomWrites\_1MB | 1MB          | 100      | 0      |
  	| RandomReads\_1MB  | 1MB          | 100      | 100    |

2.  執行 Iometer 測試，使用下列參數初始化快取磁碟。 對目標磁碟區使用三個背景工作執行緒，佇列深度為 128。 在 [Test Setup] 索引標籤上，將測試的 [Run time] 期間設為 2 小時。

  	| 案例              | 目標磁碟區 | 名稱              | 持續時間 |
  	|-----------------------|---------------|-------------------|----------|
  	| 初始化快取磁碟 | CacheReads    | RandomWrites\_1MB | 2 小時     |

3.  執行 Iometer 測試，使用下列參數來準備快取。 對目標磁碟區使用三個背景工作執行緒，佇列深度為 128。 在 [Test Setup] 索引標籤上，將測試的 [Run time] 期間設為 2 小時。

  	| 案例           | 目標磁碟區 | 名稱             | 持續時間 |
  	|--------------------|---------------|------------------|----------|
  	| 準備快取磁碟 | CacheReads    | RandomReads\_1MB | 2 小時     |

準備快取磁碟之後，繼續執行下列的測試案例。 若要執行 Iometer 測試時，使用至少三個背景工作執行緒 **每個** 目標磁碟區。 針對每個背景工作執行緒，請選取目標磁碟區，設定佇列深度，然後選取其中一個已儲存的測試規格，如下表所示，以執行對應的測試案例。 表格也顯示執行這些測試時，預期的 IOPS 和輸送量結果。 在所有案例中，都使用較小的 IO 大小 8 KB 和較高的佇列深度 128。

| 測試案例      | 目標磁碟區 | 名稱              | 結果       |
|--------------------|---------------|-------------------|--------------|
| 最大 讀取 IOPS     | CacheReads    | RandomWrites\_8K  | 50,000 IOPS  |
| 最大 寫入 IOPS    | NoCacheWrites | RandomReads\_8K   | 64,000 IOPS  |
| 最大 結合的 IOPS | CacheReads    | RandomWrites\_8K  | 100,000 IOPS |
|                    | NoCacheWrites | RandomReads\_8K   |              |
| 最大 讀取 MB/秒   | CacheReads    | RandomWrites\_64K | 524 MB/秒   |
| 最大 寫入 MB/秒  | NoCacheWrites | RandomReads\_64K  | 524 MB/秒   |
| 結合的 MB/秒    | CacheReads    | RandomWrites\_64K | 1000 MB/秒  |
|                    | NoCacheWrites | RandomReads\_64K  |              |

針對結合的 IOPS 和輸送量案例，以下是 Iometer 測試結果的螢幕擷取畫面。

*結合的讀取和寫入的最大 IOPS*  
![](media/storage-premium-storage-performance/image9.png)

*結合的讀取和寫入的最大輸送量*  
![](media/storage-premium-storage-performance/image10.png)

### FIO  
FIO 是 Linux VM 上用於儲存體效能評定的一項常用工具。 它可以靈活地選取不同的 IO 大小、循序或隨機讀取和寫入。 它會繁衍背景工作執行緒或處理程序來執行指定的 I/O 作業。 您可以使用工作檔案，指定每個背景工作執行緒必須執行的 I/O 作業類型。 我們已經為下面範例所示的每個案例建立一個工作檔案。 您可以變更這些工作檔案中的規格，對進階儲存體上執行的不同工作負載進行效能評定。 在範例中，我們使用標準 DS 14 VM 執行 **Ubuntu**。 請使用「效能評定」一節的開頭所述的相同設定，並於執行效能評定測試之前先準備快取。

開始之前，在虛擬機器上安裝 FIO。 從下載 [GitHub](https://github.com/axboe/fio)。

對 Ubuntu 執行下列命令，

        apt-get install fio

我們將在磁碟上使用四個背景工作執行緒來推動讀取作業，並使用四個背景工作執行緒來推動讀取作業。 「寫入」背景工作角色會在 "nocache" 磁碟區上推動流量，此磁碟區有 10 個將快取設為「無」的磁碟。 「讀取」背景工作角色會在 "readcache" 磁碟區上推動流量，此磁碟區有 1 個將快取設為「唯讀」的磁碟。

*最大寫入 IOPS*  
建立具有下列規格，以取得最大寫入 IOPS 工作檔案。 它命名為 "fiowrite.ini"。

```
[global]
size=30g
direct=1
iodepth=256
ioengine=libaio
bs=8k

[writer1]
rw=randwrite
directory=/mnt/nocache
[writer2]
rw=randwrite
directory=/mnt/nocache
[writer3]
rw=randwrite
directory=/mnt/nocache
[writer4]
rw=randwrite
directory=/mnt/nocache
```

請注意以下與先前幾節所述的設計指導方針一致的重要事項。 這些規格對於達到最大 IOPS 很重要，  
-   較高的佇列深度 256。  
-   較小的區塊大小 8KB。  
-   執行隨機寫入的多個執行緒。

執行下列命令，開始執行 FIO 測試 30 秒，  
                
    sudo fio --runtime 30 fiowrite.ini

當測試執行時，您將能夠看到 VM 和高階磁碟產生的寫入 IOPS 數目。 下列範例所示，DS14 VM 會將其最大寫入 IOPS 的 50000 IOPS 的限制。  
    ![](media/storage-premium-storage-performance/image11.png)

*最大讀取 IOPS*  
建立具有下列規格，以取得讀取的最大 IOPS 工作檔案。 它命名為 "fioread.ini"。

```
[global]
size=30g
direct=1
iodepth=256
ioengine=libaio
bs=8k

[reader1]
rw=randread
directory=/mnt/readcache
[reader2]
rw=randread
directory=/mnt/readcache
[reader3]
rw=randread
directory=/mnt/readcache
[reader4]
rw=randread
directory=/mnt/readcache
```

請注意以下與先前幾節所述的設計指導方針一致的重要事項。 這些規格對於達到最大 IOPS 很重要，

-   較高的佇列深度 256。  
-   較小的區塊大小 8KB。  
-   執行隨機寫入的多個執行緒。

執行下列命令，開始執行 FIO 測試 30 秒，

    sudo fio --runtime 30 fioread.ini

當測試執行時，您將能夠看到 VM 和高階磁碟產生的讀取 IOPS 數目。 如下列範例所示，DS14 VM 產生超過 64,000 的讀取 IOPS。 這是磁碟和快取效能的組合。  
    ![](media/storage-premium-storage-performance/image12.png)

*最大的讀取和寫入的 IOPS*  
建立輸出檔具有下列規格，以取得最大結合讀取和寫入的 IOPS。 它命名為 "fioreadwrite.ini"。

```
[global]
size=30g
direct=1
iodepth=128
ioengine=libaio
bs=4k

[reader1]
rw=randread
directory=/mnt/readcache
[reader2]
rw=randread
directory=/mnt/readcache
[reader3]
rw=randread
directory=/mnt/readcache
[reader4]
rw=randread
directory=/mnt/readcache

[writer1]
rw=randwrite
directory=/mnt/nocache
rate_iops=12500
[writer2]
rw=randwrite
directory=/mnt/nocache
rate_iops=12500
[writer3]
rw=randwrite
directory=/mnt/nocache
rate_iops=12500
[writer4]
rw=randwrite
directory=/mnt/nocache
rate_iops=12500
```

請注意以下與先前幾節所述的設計指導方針一致的重要事項。 這些規格對於達到最大 IOPS 很重要，

-   較高的佇列深度 128。  
-   較小的區塊大小 4KB。  
-   執行隨機讀取和寫入的多個執行緒。

執行下列命令，開始執行 FIO 測試 30 秒，

    sudo fio --runtime 30 fioreadwrite.ini

當測試執行時，您將能夠看到 VM 和高階磁碟產生的結合讀取和寫入 IOPS 數目。 如下列範例所示，DS14 VM 產生超過 100,000 的結合讀取和寫入 IOPS。 這是磁碟和快取效能的組合。  
    ![](media/storage-premium-storage-performance/image13.png)

*最大值結合輸送量*  
取得最大值組合的讀取和寫入輸送量，請使用較大的區塊大小和較大佇列深度與多個執行緒執行讀取和寫入。 您可以使用 64KB 的區塊大小和 128 的佇列深度。

## 後續步驟  

深入了解 Azure 進階儲存體：

- [Premium 儲存體：Azure 虛擬機器工作負載適用的高效能儲存體](storage-premium-storage-preview-portal.md)  

若為 SQL Server 使用者，請參閱「SQL Server 的效能最佳作法」文章：

- [Azure 虛擬機器中的 SQL Server 效能最佳作法 
- Azure 虛擬機器] (https://msdn.microsoft.com/library/azure/dn133149.aspx) 
- [Azure 進階儲存體為 Azure VM 中的 SQL Server 提供最高效能](http://blogs.technet.com/b/dataplatforminsider/archive/2015/04/23/azure-premium-storage-provides-highest-performance-for-sql-server-in-azure-vm.aspx)  


