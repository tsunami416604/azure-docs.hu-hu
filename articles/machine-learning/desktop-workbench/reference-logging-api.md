---
title: Az Azure ML-naplózás API-referencia |} Microsoft Docs
description: A naplózás API-hivatkozás.
services: machine-learning
author: akshaya-a
ms.author: akannava
manager: mwinkle
ms.reviewer: garyericson, jasonwhowell, mldocs
ms.service: machine-learning
ms.workload: data-services
ms.topic: article
ms.date: 09/25/2017
ms.openlocfilehash: 1906425c6657fb6232a9dc306b05f9171c9c7bef
ms.sourcegitcommit: 59914a06e1f337399e4db3c6f3bc15c573079832
ms.translationtype: MT
ms.contentlocale: hu-HU
ms.lasthandoff: 04/19/2018
---
# <a name="logging-api-reference"></a>Naplózás API-referencia

Az Azure ML naplózási könyvtár lehetővé teszi, hogy a program létrehozza a metrikák és újabb analysis előzmények szolgáltatás által nyomon követett fájlokat. Jelenleg néhány alapvető típusú metrikák és a fájlok támogatottak, és a jövőbeni kiadásokban a Python-csomag nő a támogatott típusok készlete.

## <a name="uploading-metrics"></a>Metrikák feltöltése

```python
# import logging API package
from azureml.logging import get_azureml_logger

# initialize a logger object
logger = get_azureml_logger()

# log "scalar" metrics
logger.log("simple integer value", 7)
logger.log("simple float value", 3.141592)
logger.log("simple string value", "this is a string metric")

# log a list of numerical values. 
# this automatically creates a chart in the Run History details page
logger.log("chart data points", [1, 3, 5, 10, 6, 4])
```

Alapértelmezés szerint minden metrikák elküldi aszinkron módon, hogy a küldése nem akadályozzák a program végrehajtásával. Rendezési problémákat okozhatnak, amikor több metrikák küldött peremhálózati esetekben. Példa erre egy időben, de a felhasználó inkább megőrzi a pontos rendelési valamilyen okból naplózott két metrikák lenne. Egy másik helyzet akkor, ha a mérték előtt esetleg sikertelen lesz a gyors néhány kódot futtató ismert nyomon követését. Mindkét esetben a megoldás, hogy _Várjon, amíg_ mindaddig, amíg a metrika teljes mértékben naplózza a folytatás előtt:

```python
# blocking call
logger.log("my metric 1", 1).wait()
logger.log("my metric 2", 2).wait()
```

## <a name="consuming-metrics"></a>Metrikák felhasználása

A metrikák az Előzmények szolgáltatás által tárolt, és a Futtatás előállított őket kötve. A Futtatás Előzmények lapon és a parancssori felület parancs az alábbi teszik lekérdezéséhez őket (vagy az alábbi összetevők) futtató befejeződése után.

```azurecli
# show the last run
$ az ml history last

# list all past runs
$ az ml history list 

# show a paritcular run
$ az ml history info -r <runid>
```

## <a name="artifacts-files"></a>Az összetevők (fájlok)

Metrikák, valamint az AzureML a felhasználó nyomon követéséhez a fájlokat is. Alapértelmezés szerint minden fájl bekerül a `outputs` viszonyítva (a projektmappa a számítási környezetben). a program munkakönyvtár mappa az Előzmények szolgáltatás fel van töltve, és újabb analysis követi nyomon. Szerint, hogy az egyes fájlméret 512 MB-nál kisebbnek kell lennie.


```Python
# Log content as an artifact
logger.upload("artifact/path", "This should be the contents of artifact/path in the service")
```

## <a name="consuming-artifacts"></a>Az összetevők felhasználása

Követett összetevő tartalmának nyomtatása felhasználó használja a Futtatás Előzmények lapon a megadott futtató **letöltése** vagy **előléptetés** összetevő, vagy használja az alábbi ugyanaz az eredmény elérése érdekében a parancssori felület parancsait.

```azurecli
# show all artifacts generated by a run
$ az ml history info -r <runid> -a <artifact/path>

# promote a particular artifact
$ az ml history promote -r <runid> -ap <artifact/prefix> -n <name of asset to create>
```
## <a name="next-steps"></a>További lépések
- Végezze el a [zárolásának iris tutoria, 2. rész](tutorial-classifying-iris-part-2.md) naplózási API-t működés közben megjelenítéséhez.
- Felülvizsgálati [használata futtatása előzmények és az Azure Machine Learning-munkaterület modell metrikák](how-to-use-run-history-model-metrics.md) megértéséhez mélyebb hogyan API-k naplózása használható futtassa az előzményekben.
